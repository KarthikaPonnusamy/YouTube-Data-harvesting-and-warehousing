{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api = \"AIzaSyDzl66H0MC5G9UZ8HU0b3BxdOOIYl7ERAA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pymongo\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from datetime import datetime\n",
    "import time\n",
    "from dateutil import parser\n",
    "import dateutil.parser\n",
    "import re\n",
    "\n",
    "#youtube_API connect\n",
    "def Api_connect():\n",
    "    api_key = \"AIzaSyDzl66H0MC5G9UZ8HU0b3BxdOOIYl7ERAA\"\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "    return youtube\n",
    "youtube=Api_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_parse(duration):\n",
    "\n",
    "    matches = re.match(r'PT(\\d+M)?(\\d+S)?', duration)\n",
    "    #Extract minutes and seconds from the matched groups\n",
    "    duration_minutes = int(matches.group(1)[:-1]) if matches.group(1) else 0\n",
    "    duration_seconds = int(matches.group(2)[:-1]) if matches.group(2) else 0\n",
    "\n",
    "    # Convert duration to total seconds\n",
    "    duration_in_seconds = duration_minutes * 60 + duration_seconds\n",
    "\n",
    "    # Convert total seconds to hours, minutes, and seconds\n",
    "    hours, remainder = divmod(duration_in_seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    formatted_duration = \"{:02}:{:02}:{:02}\".format(int(hours), int(minutes), int(seconds))\n",
    "\n",
    "    return formatted_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel information\n",
    "\n",
    "def get_Channelinfo(Channel_id):\n",
    "    #all_data = []\n",
    "    request= youtube.channels().list(\n",
    "        part=\"Snippet,ContentDetails,statistics\",\n",
    "        id = Channel_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    #response['items'][0]['id']\n",
    "\n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(Channel_name = response['items'][i]['snippet']['title'],\n",
    "                    Channel_Id = response[\"items\"][i][\"id\"],\n",
    "                    Subscribers = response['items'][i]['statistics']['subscriberCount'],\n",
    "                    Views = response['items'][i]['statistics']['viewCount'],\n",
    "                    Total_videos = response['items'][i]['statistics']['videoCount'],\n",
    "                    Description = response['items'][i]['snippet']['description'],\n",
    "                    playlist_id = response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])\n",
    "    return data   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting video Ids\n",
    "def get_channel_videos(channel_id):\n",
    "    video_ids = []\n",
    "        \n",
    "    res = youtube.channels().list(id=channel_id, \n",
    "                                    part='contentDetails').execute()\n",
    "    playlist_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    next_page_token = None\n",
    "        \n",
    "    while True:\n",
    "        res = youtube.playlistItems().list( \n",
    "                                            part = 'snippet',\n",
    "                                            playlistId = playlist_id, \n",
    "                                            maxResults = 50,\n",
    "                                            pageToken = next_page_token).execute()\n",
    "            \n",
    "        for i in range(len(res['items'])):\n",
    "                video_ids.append(res['items'][i]['snippet']['resourceId']['videoId'])\n",
    "        next_page_token = res.get('nextPageToken')\n",
    "            \n",
    "        if next_page_token is None:\n",
    "            break\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get info for video\n",
    "def get_video_info(video_ids):\n",
    "    \n",
    "    video_data = []\n",
    "\n",
    "    for video_id in video_ids:\n",
    "            request = youtube.videos().list(\n",
    "                        part=\"snippet,contentDetails,statistics\",\n",
    "                        id= video_id)\n",
    "            response = request.execute()\n",
    "\n",
    "            for item in response[\"items\"]:\n",
    "                data = dict(Channel_Name = item['snippet']['channelTitle'],\n",
    "                            Channel_Id = item['snippet']['channelId'],\n",
    "                            Video_Id = item['id'],\n",
    "                            Title = item['snippet']['title'],\n",
    "                            Tags = item['snippet'].get('tags'),\n",
    "                            Thumbnail = item['snippet']['thumbnails']['default']['url'],\n",
    "                            Description = item['snippet']['description'],\n",
    "                            Published_Date = item['snippet']['publishedAt'],\n",
    "                            Duration = time_parse(item['contentDetails']['duration']),\n",
    "                            Views = item['statistics']['viewCount'],\n",
    "                            Likes = item['statistics'].get('likeCount'),\n",
    "                            Comments = item['statistics'].get('commentCount'),\n",
    "                            Favorite_Count = item['statistics']['favoriteCount'],\n",
    "                            Definition = item['contentDetails']['definition'],\n",
    "                            Caption_Status = item['contentDetails']['caption']\n",
    "                            )\n",
    "                video_data.append(data)\n",
    "            #print(video_data)\n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting info for command\n",
    "def get_comment_info(video_ids):\n",
    "        Comment_Information = []\n",
    "        try:\n",
    "                for video_id in video_ids:\n",
    "\n",
    "                        request = youtube.commentThreads().list(\n",
    "                                part = \"snippet\",\n",
    "                                videoId = video_id,\n",
    "                                maxResults = 50\n",
    "                                )\n",
    "                        response5 = request.execute()\n",
    "                        \n",
    "                        for item in response5[\"items\"]:\n",
    "                                comment_information = dict(\n",
    "                                        Comment_Id = item[\"snippet\"][\"topLevelComment\"][\"id\"],\n",
    "                                        Video_Id = item[\"snippet\"][\"videoId\"],\n",
    "                                        Comment_Text = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textOriginal\"],\n",
    "                                        Comment_Author = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"authorDisplayName\"],\n",
    "                                        Comment_Published = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"])\n",
    "\n",
    "                                Comment_Information.append(comment_information)\n",
    "        except:\n",
    "                pass\n",
    "              \n",
    "        return Comment_Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting info of playlist\n",
    "def get_Playlist_details(channel_id):\n",
    "        next_page_token = None\n",
    "        All_data=[]\n",
    "        while True:\n",
    "                request = youtube.playlists().list( \n",
    "                        part='snippet,contentDetails',\n",
    "                        channelId=channel_id,\n",
    "                        maxResults=50,\n",
    "                        pageToken=next_page_token\n",
    "                )\n",
    "                response = request.execute()\n",
    "\n",
    "                for item in response['items']:\n",
    "                        data = dict(Playlist_Id=item['id'],\n",
    "                                        Title=item['snippet']['title'],\n",
    "                                        channelId=item['snippet']['channelId'],\n",
    "                                        channel_Name=item['snippet']['channelTitle'],\n",
    "                                        PublishedAt=item['snippet']['publishedAt'],\n",
    "                                        Video_count=item['contentDetails']['itemCount'])\n",
    "                        All_data.append(data)\n",
    "                next_page_token=response.get('nextPageToken')\n",
    "                if next_page_token is None:\n",
    "                        break \n",
    "        return All_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=pymongo.MongoClient(\"mongodb+srv://pkarthika923:karthikamongo@cluster0.iychizj.mongodb.net/?retryWrites=true&w=majority\")\n",
    "\n",
    "db=client[\"Youtube_data\"]\n",
    "information = db[\"channel_details\"]\n",
    "record = {\n",
    "    \"fn\":\"karthika\",\n",
    "    \"city\":\"cbe\",\n",
    "    \"age\":27\n",
    "}\n",
    "\n",
    "information.insert_one(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranfer/upload data to mongoDB\n",
    "client=pymongo.MongoClient(\"mongodb+srv://pkarthika923:karthikamongo@cluster0.iychizj.mongodb.net/?retryWrites=true&w=majority\")\n",
    "db=client[\"Youtube_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_details(channel_id):\n",
    "\n",
    "    ch_details=get_Channelinfo(channel_id)\n",
    "    pl_details=get_Playlist_details(channel_id)\n",
    "    vi_ids=get_channel_videos(channel_id)\n",
    "    vi_details=get_video_info(vi_ids)\n",
    "    com_details=get_comment_info(vi_ids)\n",
    "\n",
    "    coll1=db['channel_details']\n",
    "    coll1.insert_one({\"channel_information\":ch_details,\"playlist_information\":pl_details,\n",
    "                    \"video_information\":vi_details,\"comment_information\":com_details})\n",
    "\n",
    "    return \"uploaded successfully\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert channel details\n",
    "# UCn4VJ4i4u6VP2GzlbrKNhsA - missaikavi\n",
    "# UCtVIjcbuUX3p1NV77dkaPmg - dromo\n",
    "\n",
    "\n",
    "insert=channel_details('UCtVIjcbuUX3p1NV77dkaPmg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Channel table/mongo-sql\n",
    "def channels_table():\n",
    "    mydb = pymysql.connect(host=\"127.0.0.1\",\n",
    "                    user=\"root\",\n",
    "                    password=\"admin@123\",\n",
    "                    database= \"youtube_data\"\n",
    "                    )\n",
    "    cursor = mydb.cursor()\n",
    "    \n",
    "    drop_query='''drop table if exists channels'''\n",
    "    cursor.execute(drop_query)\n",
    "\n",
    "    try:\n",
    "\n",
    "        create_query = '''create table if not exists channels(Channel_Name varchar(100),\n",
    "                                                        Channel_Id varchar(80) primary key, \n",
    "                                                        Subscription_Count bigint, \n",
    "                                                        Views bigint,\n",
    "                                                        Total_Videos int,\n",
    "                                                        Channel_Description text,\n",
    "                                                        Playlist_Id varchar(50))'''\n",
    "        cursor.execute(create_query)\n",
    "        \n",
    "    except:\n",
    "        print(\"Channel table already created\")\n",
    "\n",
    "    ch_list=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_list.append(ch_data[\"channel_information\"])\n",
    "    df=pd.DataFrame(ch_list)\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        \n",
    "        insert_query = '''insert into channels(Channel_Name,\n",
    "                                            Channel_Id,\n",
    "                                            Subscription_Count,\n",
    "                                            Views,\n",
    "                                            Total_Videos,\n",
    "                                            Channel_Description,\n",
    "                                            Playlist_Id )\n",
    "                                            values(%s,%s,%s,%s,%s,%s,%s)'''\n",
    "                                            \n",
    "        values = (row['Channel_name'],\n",
    "                row['Channel_Id'],\n",
    "                row['Subscribers'],\n",
    "                row['Views'],\n",
    "                row['Total_videos'],\n",
    "                row['Description'],\n",
    "                row['playlist_id'])\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(insert_query,values)  \n",
    "            mydb.commit()      \n",
    "        except:\n",
    "            print(\"Channels values are already inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playlist table creationplaylist_table\n",
    "\n",
    "def playlist_table():\n",
    "    mydb = pymysql.connect(host=\"127.0.0.1\",\n",
    "                    user=\"root\",\n",
    "                    password=\"admin@123\",\n",
    "                    database= \"youtube_data\"\n",
    "                    )\n",
    "    cursor = mydb.cursor()\n",
    "    drop_query='''drop table if exists playlists'''\n",
    "    cursor.execute(drop_query)\n",
    "\n",
    "    try:\n",
    "        create_query = '''CREATE TABLE IF NOT EXISTS playlists (PlaylistId VARCHAR(100) PRIMARY KEY,\n",
    "                                                                Title VARCHAR(80),\n",
    "                                                                ChannelId VARCHAR(100),\n",
    "                                                                ChannelName VARCHAR(100),\n",
    "                                                                PublishedAt VARCHAR(50),\n",
    "                                                                VideoCount INT\n",
    "                                    )\n",
    "        '''\n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        print(\"Play list values are already added\")\n",
    "    \n",
    "#playlist insert data\n",
    "\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 =db[\"channel_details\"]\n",
    "    pl_list = []\n",
    "    for pl_data in coll1.find({},{\"_id\":0,\"playlist_information\":1}):\n",
    "        for i in range(len(pl_data[\"playlist_information\"])):\n",
    "                pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "    df = pd.DataFrame(pl_list)\n",
    "    try:\n",
    "        for index,row in df.iterrows():\n",
    "            insert_query = '''INSERT into playlists(PlaylistId,\n",
    "                                                        Title,\n",
    "                                                        ChannelId,\n",
    "                                                        ChannelName,\n",
    "                                                        PublishedAt,\n",
    "                                                        VideoCount)\n",
    "                                            VALUES(%s,%s,%s,%s,%s,%s)'''            \n",
    "            values =(\n",
    "                    row['Playlist_Id'],\n",
    "                    row['Title'],\n",
    "                    row['channelId'],\n",
    "                    row['channel_Name'],\n",
    "                    row['PublishedAt'],\n",
    "                    row['Video_count'])\n",
    "                    \n",
    "                                \n",
    "            cursor.execute(insert_query,values)\n",
    "            mydb.commit()\n",
    "\n",
    "    except:\n",
    "            print(\"Channels values are already inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comments table\n",
    "def comments_table():\n",
    "    mydb = pymysql.connect(host=\"127.0.0.1\",\n",
    "                user=\"root\",\n",
    "                password=\"admin@123\",\n",
    "                database= \"youtube_data\"\n",
    "                )\n",
    "    cursor = mydb.cursor()\n",
    " \n",
    "    drop_query='''drop table if exists comments'''\n",
    "    cursor.execute(drop_query)\n",
    "\n",
    "    create_query = '''create table if not exists comments(Comment_Id varchar(100) PRIMARY KEY,\n",
    "                                        Video_Id varchar(50),\n",
    "                                        Comment_Text text,\n",
    "                                        Comment_Author varchar(150),\n",
    "                                        Comment_Published varchar(50))'''\n",
    "    cursor.execute(create_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    cm_list=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for cm_data in coll1.find({},{\"_id\":0,\"comment_information\":1}):\n",
    "        for i in range(len(cm_data[\"comment_information\"])):\n",
    "            cm_list.append(cm_data[\"comment_information\"][i])\n",
    "            df3=pd.DataFrame(cm_list)\n",
    "            \n",
    "            for index,row in df3.iterrows():\n",
    "                insert_query = '''insert into comments(Comment_Id,\n",
    "                                            Video_Id,\n",
    "                                            Comment_Text,\n",
    "                                            Comment_Author,\n",
    "                                            Comment_Published)\n",
    "                                            values(%s,%s,%s,%s,%s)'''\n",
    "                                            \n",
    "                values = (row['Comment_Id'],\n",
    "                        row['Video_Id'],\n",
    "                        row['Comment_Text'],\n",
    "                        row['Comment_Author'],\n",
    "                        row['Comment_Published']\n",
    "                )\n",
    "              \n",
    "                try:\n",
    "                    print(insert_query,values)\n",
    "                    cursor.execute(insert_query,values)\n",
    "                    mydb.commit()\n",
    "                except:\n",
    "                    print(\"Comments are already inserted\")\n",
    "                   \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#playlist insert data\n",
    "\n",
    "db = client[\"Youtube_data\"]\n",
    "coll1 =db[\"channel_details\"]\n",
    "pl_list = []\n",
    "for pl_data in coll1.find({},{\"_id\":0,\"playlist_information\":1}):\n",
    "    for i in range(len(pl_data[\"playlist_information\"])):\n",
    "            pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "df = pd.DataFrame(pl_list)\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    insert_query = '''INSERT into playlists(PlaylistId,\n",
    "                                                Title,\n",
    "                                                ChannelId,\n",
    "                                                ChannelName,\n",
    "                                                PublishedAt,\n",
    "                                                VideoCount)\n",
    "                                    VALUES(%s,%s,%s,%s,%s,%s)'''            \n",
    "    values =(\n",
    "            row['Playlist_Id'],\n",
    "            row['Title'],\n",
    "            row['channelId'],\n",
    "            row['channel_Name'],\n",
    "            row['PublishedAt'],\n",
    "            row['Video_count'])\n",
    "            \n",
    "                        \n",
    "    cursor.execute(insert_query,values)\n",
    "    print(insert_query,values)\n",
    "    mydb.commit()    \n",
    "    \n",
    "       # print(\"Playlists values are already inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymysql.cursors.Cursor object at 0x00000241D52DF8F0>\n"
     ]
    }
   ],
   "source": [
    "#table creation for videos\n",
    "\n",
    "mydb = pymysql.connect(host=\"127.0.0.1\",\n",
    "                user=\"root\",\n",
    "                password=\"admin@123\",\n",
    "                database= \"youtube_data\"\n",
    "                )\n",
    "cursor = mydb.cursor()\n",
    "print(cursor)\n",
    "drop_query='''drop table if exists videosdata'''\n",
    "cursor.execute(drop_query)\n",
    "\n",
    "create_query = '''create table if not exists videosdata(Channel_Name varchar(150),\n",
    "                                                    Channel_Id varchar(150),\n",
    "                                                    Video_Id varchar(75), \n",
    "                                                    Title varchar(500), \n",
    "                                                    Tags text,\n",
    "                                                    Thumbnail varchar(400),\n",
    "                                                    Description text, \n",
    "                                                    Published_Date varchar(150),\n",
    "                                                    Duration time,\n",
    "                                                    Views int, \n",
    "                                                    Likes int,\n",
    "                                                    Comments int,\n",
    "                                                    Favorite_Count int, \n",
    "                                                    Definition varchar(50), \n",
    "                                                    Caption_Status varchar(50) \n",
    "                        )''' \n",
    "#print(create_query)\n",
    "cursor.execute(create_query)\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert query for videos table\n",
    "vi_list=[]\n",
    "db=client[\"Youtube_data\"]\n",
    "coll1=db[\"channel_details\"]\n",
    "for vi_data in coll1.find({},{\"_id\":0,\"video_information\":1}):\n",
    "    for i in range(len(vi_data[\"video_information\"])):\n",
    "        vi_list.append(vi_data[\"video_information\"][i])\n",
    "df2=pd.DataFrame(vi_list)\n",
    "\n",
    "#print(df2)\n",
    "\n",
    "\n",
    "for index,row in df2.iterrows():\n",
    "    Tags= str(row['Tags']).replace('[','').replace(']','')\n",
    "\n",
    "\n",
    "    insert_query ='''insert into videosdata(Channel_Name,\n",
    "                                        Channel_Id,\n",
    "                                        Video_Id, \n",
    "                                        Title,\n",
    "                                        Tags,\n",
    "                                        Thumbnail,\n",
    "                                        Description,\n",
    "                                        Published_Date,\n",
    "                                        Duration,\n",
    "                                        Views,\n",
    "                                        Likes,\n",
    "                                        Comments,\n",
    "                                        Favorite_Count,\n",
    "                                        Definition,\n",
    "                                        Caption_Status)VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)'''\n",
    "    \n",
    "   \n",
    "\n",
    "    values = (row['Channel_Name'],\n",
    "            row['Channel_Id'], \n",
    "            row['Video_Id'], \n",
    "            row['Title'], \n",
    "            Tags,\n",
    "            row['Thumbnail'], \n",
    "            row['Description'], \n",
    "            row['Published_Date'], \n",
    "            row['Duration'], \n",
    "            row['Views'], \n",
    "            row['Likes'], \n",
    "            row['Comments'],\n",
    "            row['Favorite_Count'],\n",
    "            row['Definition'], \n",
    "            row['Caption_Status'])\n",
    "   \n",
    "    cursor.execute(insert_query,values)\n",
    "    mydb.commit()\n",
    "   \n",
    "    print(insert_query,values)    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymysql.cursors.Cursor object at 0x0000018A513C9880>\n"
     ]
    }
   ],
   "source": [
    "#table creation for comments\n",
    "mydb = pymysql.connect(host=\"127.0.0.1\",\n",
    "                user=\"root\",\n",
    "                password=\"admin@123\",\n",
    "                database= \"youtube_data\"\n",
    "                )\n",
    "cursor = mydb.cursor()\n",
    "print(cursor)\n",
    "drop_query='''drop table if exists comments'''\n",
    "cursor.execute(drop_query)\n",
    "\n",
    "create_query = '''create table if not exists comments(Comment_Id varchar(100) primary key,\n",
    "                                        Video_Id varchar(50),\n",
    "                                        Comment_Text text,\n",
    "                                        Comment_Author varchar(150),\n",
    "                                        Comment_Published varchar(50))'''\n",
    "cursor.execute(create_query)\n",
    "\n",
    "cm_list=[]\n",
    "db=client[\"Youtube_data\"]\n",
    "coll1=db[\"channel_details\"]\n",
    "for cm_data in coll1.find({},{\"_id\":0,\"comment_information\":1}):\n",
    "    for i in range(len(cm_data[\"comment_information\"])):\n",
    "        cm_list.append(cm_data[\"comment_information\"][i])\n",
    "df3=pd.DataFrame(cm_list)\n",
    "\n",
    "for index,row in df3.iterrows():\n",
    "        #print(index,row)\n",
    "        insert_query = '''insert into comments(Comment_Id,\n",
    "                                            Video_Id,\n",
    "                                            Comment_Text,\n",
    "                                            Comment_Author,\n",
    "                                            Comment_Published)\n",
    "                                            values(%s,%s,%s,%s,%s)'''\n",
    "                                            \n",
    "        values = (row['Comment_Id'],\n",
    "                row['Video_Id'],\n",
    "                row['Comment_Text'],\n",
    "                row['Comment_Author'],\n",
    "                row['Comment_Published']\n",
    "               )\n",
    "        try:\n",
    "                cursor.execute(insert_query,values)\n",
    "                mydb.commit()\n",
    "        except:\n",
    "              print(\"hi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_list=[]\n",
    "db=client[\"Youtube_data\"]\n",
    "coll1=db[\"channel_details\"]\n",
    "for cm_data in coll1.find({},{\"_id\":0,\"comment_information\":1}):\n",
    "    for i in range(len(cm_data[\"comment_information\"])):\n",
    "        cm_list.append(cm_data[\"comment_information\"][i])\n",
    "df3=pd.DataFrame(cm_list)\n",
    "\n",
    "for index,row in df3.iterrows():\n",
    "        #print(index,row)\n",
    "        insert_query = '''insert into comments(Comment_Id,\n",
    "                                            Video_Id,\n",
    "                                            Comment_Text,\n",
    "                                            Comment_Author,\n",
    "                                            Comment_Published)\n",
    "                                            values(%s,%s,%s,%s,%s)'''\n",
    "                                            \n",
    "        values = (row['Comment_Id'],\n",
    "                row['Video_Id'],\n",
    "                row['Comment_Text'],\n",
    "                row['Comment_Author'],\n",
    "                row['Comment_Published']\n",
    "               )\n",
    "        try:\n",
    "                cursor.execute(insert_query,values)\n",
    "                mydb.commit()\n",
    "        except:\n",
    "              print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tables():\n",
    "    channels_table()\n",
    "    videos_table()\n",
    "    playlist_table()\n",
    "    comments_table()\n",
    "\n",
    "    return \"Table created successfully\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channels_table():\n",
    "    ch_list=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_list.append(ch_data[\"channel_information\"])\n",
    "    df=st.dataframe(ch_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_playlist_table():\n",
    "    pl_list=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for pl_data in coll1.find({},{\"_id\":0,\"playlist_information\":1}):\n",
    "        for i in range(len(pl_data[\"playlist_information\"])):\n",
    "            pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "    df1=st.dataframe(pl_list)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_videos_table():\n",
    "    vi_list=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for vi_data in coll1.find({},{\"_id\":0,\"video_information\":1}):\n",
    "        for i in range(len(vi_data[\"video_information\"])):\n",
    "            vi_list.append(vi_data[\"video_information\"][i])\n",
    "    df2=st.dataframe(vi_list)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_comments_table():\n",
    "    cm_list=[]\n",
    "    db=client[\"Youtube_data\"]\n",
    "    coll1=db[\"channel_details\"]\n",
    "    for cm_data in coll1.find({},{\"_id\":0,\"comment_information\":1}):\n",
    "        for i in range(len(cm_data[\"comment_information\"])):\n",
    "            cm_list.append(cm_data[\"comment_information\"][i])\n",
    "    df3=st.dataframe(cm_list)\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output - streamlit\n",
    "#UI\n",
    "with st.sidebar:\n",
    "    st.title(\":red[ youTube DATA HARVESTING AS WAREHOUSING]\")\n",
    "    st.header(\"Skill take away\")\n",
    "    st.caption(\"Python scripting\")\n",
    "    st.caption(\"Data collection\")\n",
    "    st.caption(\"MongoDB\")\n",
    "    st.caption(\"API integration\")\n",
    "    st.caption(\"Data management  using mongoDB\")\n",
    "#CHECK CHANNELS IDS\n",
    "    channel_id=st.text_input(\"Enter the channel Id\")\n",
    "    if st.button(\"collect and store data\"):\n",
    "        ch_ids = []\n",
    "        db=client[\"Youtube_data\"]\n",
    "        coll1=db[\"channel_details\"]\n",
    "        for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "            ch_ids.append(ch_data['channel_information']['Channel_Id'])\n",
    "\n",
    "        if channel_id in  ch_ids:\n",
    "            st.success(\"Entered channel Ids details already exists\")\n",
    "        else:\n",
    "            insert=channel_details(channel_id)\n",
    "            st.success(insert)\n",
    "\n",
    "#MIGRATE TO SQL\n",
    "if st.button(\"Migrate to sql\"):\n",
    "    Table=tables()\n",
    "    st.success(Table)\n",
    "\n",
    "#VIEW TABLES\n",
    "show_tables=st.radio(\"Please select the below options to view in table\",(\"Channels\",\"Playlists\",\"Videos\",\"Comments\"))\n",
    "\n",
    "if show_tables==\"Channels\":\n",
    "    show_channels_table()\n",
    "elif show_tables==\"Playlists\":\n",
    "    show_playlist_table()\n",
    "elif show_tables==\"Videos\":   \n",
    "    show_videos_table()\n",
    "elif show_tables==\"Comments\":\n",
    "    show_comments_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql connection-10 question\n",
    "mydb = pymysql.connect(host=\"127.0.0.1\",\n",
    "                user=\"root\",\n",
    "                password=\"admin@123\",\n",
    "                database= \"youtube_data\"\n",
    "                )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "question = st.selectbox('Please Select Your Question',\n",
    "                        ('1. All the videos and the Channel Name',\n",
    "                        '2. Channels with most number of videos',\n",
    "                        '3. 10 most viewed videos',\n",
    "                        '4. Comments in each video',\n",
    "                        '5. Videos with highest likes',\n",
    "                        '6. likes of all videos',\n",
    "                        '7. views of each channel',\n",
    "                        '8. videos published in the year 2022',\n",
    "                        '9. average duration of all videos in each channel',\n",
    "                        '10. videos with highest number of comments'))\n",
    "\n",
    "if question==\"1. All the videos and the Channel Name\":\n",
    "    query1 = ''' select Channel_Name as channels ,Title as videos from videosdata'''\n",
    "    cursor.execute(query1)\n",
    "    t1=cursor.fetchall()\n",
    "    df1=pd.DataFrame(t1,columns=[\"video\",\"channel_name\"])\n",
    "    st.write(df1)\n",
    "\n",
    "elif question==\"2. Channels with most number of videos\":\n",
    "    query2 = ''' select Channel_Name as channels ,Total_Videos as total_videos from channels order by total_videos desc'''\n",
    "    cursor.execute(query2)\n",
    "    t2=cursor.fetchall()\n",
    "    df2=pd.DataFrame(t2,columns=[\"Channel_Name\",\"No of videos\"])\n",
    "    st.write(df2)\n",
    "\n",
    "elif question==(\"3. 10 most viewed videos\"):\n",
    "    query3 = ''' select Channel_Name as channels,Title as videos,Views as views from videosdata where views is not null order by views desc limit 10'''\n",
    "    cursor.execute(query3)\n",
    "    t3=cursor.fetchall()\n",
    "    df3=pd.DataFrame(t3,columns=[\"Channel_Name\",\"Video\",\"Views\"])   \n",
    "    st.write(df3)\n",
    "\n",
    "elif question==(\"4. Comments in each video\"):\n",
    "    query4 = ''' select Channel_Name as channels,Title as videos,Comments as comments from videosdata where comments is not null'''\n",
    "    cursor.execute(query4)\n",
    "    t4=cursor.fetchall()\n",
    "    df4=pd.DataFrame(t4,columns=[\"Channel_Name\",\"Video\",\"Comments_count\"])\n",
    "    st.write(df4)\n",
    "\n",
    "elif question==(\"5. Videos with highest likes\"):\n",
    "    query5 = '''select Channel_Name ,Title ,Likes as like_count from videosdata where Likes is not null order by like_count desc'''\n",
    "    cursor.execute(query5)\n",
    "    t5=cursor.fetchall()\n",
    "    df5=pd.DataFrame(t5,columns=[\"Channel_Name\",\"Title\",\"like_count\"])\n",
    "    st.write(df5)\n",
    "\n",
    "elif question==\"6. likes of all videos\":\n",
    "    query6 = '''select Title ,Likes as like_count from videosdata where Likes is not null'''\n",
    "    cursor.execute(query6)\n",
    "    t6=cursor.fetchall()\n",
    "    df6=pd.DataFrame(t6,columns=[\"Title\",\"like_count\"])\n",
    "    st.write(df6)\n",
    "\n",
    "elif question==\"7. views of each channel\":\n",
    "    query7 = '''select Channel_Name as name,Views as view_count from channels where Views is not null'''\n",
    "    cursor.execute(query7)\n",
    "    t7=cursor.fetchall()\n",
    "    df7=pd.DataFrame(t7,columns=[\"Channel_Name\",\"view_count\"])\n",
    "    st.write(df7)\n",
    "\n",
    "elif question==\"8. videos published in the year 2022\":\n",
    "    query8 = '''select Title as video_title,Published_Date as date,Channel_Name from videosdata where extract(year from Published_date)=2022'''\n",
    "    cursor.execute(query8)\n",
    "    t8=cursor.fetchall()\n",
    "    df8=pd.DataFrame(t8,columns=[\"Video_Title\",\"Published_Date\",\"Channel_Name\"])\n",
    "    st.write(df8)\n",
    "    \n",
    "elif question==\"9. average duration of all videos in each channel\":\n",
    "    query9 = ''' select Channel_Name as channelname, SEC_TO_TIME(AVG(TIME_TO_SEC(Duration))) as avgduration from videosdata group by Channel_Name'''\n",
    "    cursor.execute(query9)\n",
    "    t9=cursor.fetchall()\n",
    "    df9=pd.DataFrame(t9,columns=[\"Channel_Name\",\"Duration_AVG\"])\n",
    "\n",
    "    TF9=[]\n",
    "    for index,row in df9.iterrows():\n",
    "        channel_title=row[\"Channel_Name\"]\n",
    "        avg_duration=row[\"Duration_AVG\"]\n",
    "        avg_duration_str=str(avg_duration)\n",
    "        TF9.append(dict(Channel_Title=channel_title,Avg_duartion=avg_duration_str))\n",
    "    df_str=pd.DataFrame(TF9)\n",
    "    st.write(df_str)\n",
    "\n",
    "\n",
    "elif question==\"10. videos with highest number of comments\":\n",
    "    query10 = ''' select Channel_Name as channels,Title as videos,Comments as comments from videosdata where comments is not null order by comments desc'''\n",
    "    cursor.execute(query10)\n",
    "    t10=cursor.fetchall()\n",
    "    df10=pd.DataFrame(t10,columns=[\"Channel_Name\",\"Video\",\"Comments_count\"])\n",
    "    st.write(df10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = pymysql.connect(host=\"127.0.0.1\",\n",
    "                user=\"root\",\n",
    "                password=\"admin@123\",\n",
    "                database= \"youtube_data\"\n",
    "                )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "query9 = ''' select Channel_Name as channelname, SEC_TO_TIME(AVG(TIME_TO_SEC(Duration))) as avgduration from videosdata group by Channel_Name'''\n",
    "cursor.execute(query9)\n",
    "t9=cursor.fetchall()\n",
    "df9=pd.DataFrame(t9,columns=[\"Channel_Name\",\"Duration_AVG\"])\n",
    "\n",
    "TF9=[]\n",
    "for index,row in df9.iterrows():\n",
    "    channel_title=row[\"Channel_Name\"]\n",
    "    avg_duration=row[\"Duration_AVG\"]\n",
    "    avg_duration_str=str(avg_duration)\n",
    "    TF9.append(dict(Channel_Title=channel_title,Avg_duartion=avg_duration_str))\n",
    "df_str=pd.DataFrame(TF9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_Title</th>\n",
       "      <th>Avg_duartion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Make Money Matt</td>\n",
       "      <td>0 days 00:14:34.334900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Missaikavi</td>\n",
       "      <td>0 days 00:01:20.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DROMOMANIACS</td>\n",
       "      <td>0 days 00:02:06.083300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Channel_Title            Avg_duartion\n",
       "0    Make Money Matt  0 days 00:14:34.334900\n",
       "1         Missaikavi  0 days 00:01:20.238000\n",
       "2       DROMOMANIACS  0 days 00:02:06.083300"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
